{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 14, 15, 31, 32, 33, 35, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "sys.path.append(pathlib.Path(\"..\").resolve().as_posix())\n",
    "\n",
    "from src.coder import TargetCoder\n",
    "from src.io_utils import write_stdout_to_file, write_df_to_csv\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 110 columns in the dataset\n",
    "# 160k+ rows\n",
    "pd.set_option('display.max_columns', 110)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "DATASET_PATH = pathlib.Path(\"..\") / \"data\" / \"raw\" / \"players.csv\"\n",
    "MAIN_COLUMNS = [7, 14, 15, 31, 32, 33, 35, 41, 42, 43, 44, 45, 46]\n",
    "DETAILED_COLUMNS =  list(range(47, 76))\n",
    "USED_COLUMNS = MAIN_COLUMNS + DETAILED_COLUMNS\n",
    "\n",
    "COLS_TO_NORMALIZE = range(0, 38)\n",
    "\n",
    "print(USED_COLUMNS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_PATH, usecols=USED_COLUMNS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Droppings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_goalkeepers(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Drops all goalkeepers from the dataset inplace\n",
    "    \"\"\"\n",
    "    df.drop(df[df[\"player_positions\"].str.contains(\"GK\")].index, inplace=True)\n",
    "    \n",
    "def drop_mentality_composure(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Drops all columns related to mentality composure\n",
    "    Reason:\n",
    "        - The column has 20k+ Nans\n",
    "    \"\"\"\n",
    "    df.drop(columns=\"mentality_composure\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proccess positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_positions(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Processes the player_positions column inplace\n",
    "    Effect:\n",
    "        - Maps the positions to the main positions (first position in the string)\n",
    "        - Move the column to the end of the dataframe\n",
    "        - Renames the column to position to \"position\"\n",
    "    \"\"\"\n",
    "    # map positions\n",
    "    df[\"player_positions\"] = df[\"player_positions\"].str.split(\",\").str[0].map(TargetCoder.map)\n",
    "    # move the column to the end\n",
    "    df[\"position\"] = df.pop(\"player_positions\")\n",
    "    \n",
    "def encode_positions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encodes the position column inplace\n",
    "    \"\"\"\n",
    "    df[\"position\"] = df[\"position\"].map(TargetCoder.encode)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One hot encode work rate & preferred_foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONCE BECAUSE THE WORKRATE COLUMNS WOULD HAVE BEEN DROPED\n",
    "def get_encoded_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes the work_rate column inplace using one hot encoding\n",
    "    Effect:\n",
    "        - Custom encode positions\n",
    "        - One hot encodes the work_rate\n",
    "        - One hot encodes the preferred_foot\n",
    "    \"\"\"\n",
    "    new_df = pd.get_dummies(df, columns=['work_rate', 'preferred_foot'])\n",
    "    new_df = encode_positions(new_df)\n",
    "    new_df[\"position\"] = new_df.pop(\"position\")\n",
    "    return new_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalizes the dataframe inplace\n",
    "    Effect:\n",
    "        - Normalizes the dataframe inplace\n",
    "    \"\"\"\n",
    "    normalized_df = df.copy()\n",
    "    normalized_df.iloc[:, COLS_TO_NORMALIZE] = scaler.fit_transform(df.iloc[:, COLS_TO_NORMALIZE])\n",
    "    return normalized_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143613, 50)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "KEEP ORDER\n",
    "\"\"\"\n",
    "\n",
    "# drop columns\n",
    "drop_goalkeepers(df)\n",
    "drop_mentality_composure(df)\n",
    "# map positions\n",
    "map_positions(df)\n",
    "\n",
    "# cleaned data\n",
    "cleaned_df = df.copy()\n",
    "# encode & normalize data\n",
    "encoded_df = get_encoded_df(cleaned_df)\n",
    "normalized_df = normalize_df(encoded_df)\n",
    "encoded_df.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_data_path = pathlib.Path(\"..\") / \"data\" / \"cleaned\" / \"cleaned_data.csv\"\n",
    "cleaned_data_info_path = pathlib.Path(\"..\") / \"data\" / \"cleaned\" / \"cleaned_data_info.txt\"\n",
    "\n",
    "processed_data_path = pathlib.Path(\"..\") / \"data\" / \"processed\" / \"processed_data.csv\"\n",
    "processed_data_info_path = pathlib.Path(\"..\") / \"data\" / \"processed\" / \"processed_data_info.txt\"\n",
    "\n",
    "encoded_data_path = pathlib.Path(\"..\") / \"data\" / \"encoded\" / \"encoded_data.csv\"\n",
    "encoded_data_info_path = pathlib.Path(\"..\") / \"data\" / \"encoded\" / \"encoded_data_info.txt\"\n",
    "\n",
    "def create_cleaned_data_files(df: pd.DataFrame) -> None:\n",
    "    write_df_to_csv(cleaned_data_path, df)\n",
    "    write_stdout_to_file(cleaned_data_info_path, lambda: df.info(verbose=True, show_counts=True))\n",
    "    \n",
    "def create_processed_data_files(df: pd.DataFrame) -> None:\n",
    "    write_df_to_csv(processed_data_path, df)\n",
    "    write_stdout_to_file(processed_data_info_path, lambda: df.info(verbose=True, show_counts=True))\n",
    "\n",
    "def create_encoded_data_files(df: pd.DataFrame) -> None:\n",
    "    write_df_to_csv(encoded_data_path, df)\n",
    "    write_stdout_to_file(encoded_data_info_path, lambda: df.info(verbose=True, show_counts=True))\n",
    "    \n",
    "# create cleaned data files\n",
    "create_cleaned_data_files(cleaned_df)\n",
    "# create encoded data files\n",
    "create_encoded_data_files(encoded_df)\n",
    "# create processed data files\n",
    "create_processed_data_files(normalized_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmps460",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
