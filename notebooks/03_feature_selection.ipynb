{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append(pathlib.Path(\"..\").resolve().as_posix())\n",
    "\n",
    "from src.io_utils import write_stdout_to_file, write_df_to_csv\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 110)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# for pca\n",
    "encoded_df = pd.read_csv(pathlib.Path(\"..\") / \"data\" / \"encoded\" / \"encoded_data.csv\")\n",
    "\n",
    "# for manual feature selection\n",
    "processed_df = pd.read_csv(pathlib.Path(\"..\") / \"data\" / \"processed\" / \"processed_data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manual Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Combine height and weight into 1 feature (Height_Weight) and insert it to the first index\n",
    "    add column to first index and remove the other 2\n",
    "\"\"\"\n",
    "MAIN_FIFA_CARD_FEATURES = ['pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic']\n",
    "ATTACKING_FEATURES = ['attacking_finishing', 'attacking_volleys', 'attacking_heading_accuracy', 'attacking_crossing']\n",
    "SKILL_FEATURES = ['skill_fk_accuracy', 'skill_ball_control', 'skill_dribbling', 'skill_curve', 'skill_long_passing']\n",
    "MOVE_FEATURES = ['movement_agility', 'movement_reactions', 'movement_balance', 'movement_acceleration', 'movement_sprint_speed']\n",
    "POWER_FEATURES = ['power_shot_power', 'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots']\n",
    "MENTAL_FEATURES = ['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties']\n",
    "DEFENDING_FEATURES = ['defending_standing_tackle', 'defending_sliding_tackle']\n",
    "EXTRA_FEATURES = [*ATTACKING_FEATURES, *SKILL_FEATURES, *MOVE_FEATURES, *POWER_FEATURES, *MENTAL_FEATURES, *DEFENDING_FEATURES]\n",
    "\n",
    "def create_height_weight_feature(df: pd.DataFrame):\n",
    "    df.insert(0, \"height_weight\", df[\"height_cm\"] + df[\"weight_kg\"] / 2)\n",
    "    df.drop([\"height_cm\", \"weight_kg\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_redundant_features(df: pd.DataFrame) -> dict:\n",
    "    redundent_features = set()\n",
    "    for main_feature in MAIN_FIFA_CARD_FEATURES:\n",
    "        for extra_feature in EXTRA_FEATURES:\n",
    "            corr = df[extra_feature].corr(df[main_feature])\n",
    "            if abs(corr) > 0.8:\n",
    "                redundent_features.add(extra_feature)\n",
    "    return list(redundent_features)\n",
    "\n",
    "def remove_features_with_high_correlation(df: pd.DataFrame, redundant_features: list) -> pd.DataFrame:\n",
    "    df.drop(redundant_features, axis=1, inplace=True)\n",
    "\n",
    "def remove_features_with_low_corr_to_position(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for feature in df.columns:\n",
    "        corr = df[feature].corr(df['position'])\n",
    "        if abs(corr) < 0.1:\n",
    "            df.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing The Weak Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_height_weight_feature(processed_df)\n",
    "relationship_graph = get_redundant_features(processed_df)\n",
    "remove_features_with_high_correlation(processed_df, relationship_graph)\n",
    "remove_features_with_low_corr_to_position(processed_df)\n",
    "\n",
    "final_data_df = processed_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def standardize_encoded_X(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    scaler = StandardScaler()\n",
    "    scaled_df = scaler.fit_transform(df.iloc[:, :-1])\n",
    "    return pd.DataFrame(scaled_df, columns=df.columns[:-1])\n",
    "    \n",
    "def apply_pca(df: pd.DataFrame, n_components: int = 6) -> np.ndarray:\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(df)\n",
    "    return pca.transform(df)\n",
    "\n",
    "n_components = 12\n",
    "standardized_X = standardize_encoded_X(encoded_df)\n",
    "pca_nd = apply_pca(standardized_X, n_components)\n",
    "pca_df = pd.DataFrame(pca_nd, columns=[f\"PC{i}\" for i in range(1, n_components+1)])\n",
    "\n",
    "pca_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_path = pathlib.Path(\"..\") / \"data\" / \"final\" / \"final_data.csv\"\n",
    "final_data_info_path = pathlib.Path(\"..\") / \"data\" / \"final\" / \"final_data_info.txt\"\n",
    "\n",
    "pca_data_path = pathlib.Path(\"..\") / \"data\" / \"final\" / \"pca_data.csv\"\n",
    "pca_data_info_path = pathlib.Path(\"..\") / \"data\" / \"final\" / \"pca_data_info.txt\"\n",
    "\n",
    "def create_final_data_files(df: pd.DataFrame) -> None:\n",
    "    write_df_to_csv(final_data_path, df)\n",
    "    write_stdout_to_file(final_data_info_path, lambda: df.info(verbose=True, show_counts=True))\n",
    "    \n",
    "def create_pca_data_files(df: pd.DataFrame) -> None:\n",
    "    write_df_to_csv(pca_data_path, df)\n",
    "    write_stdout_to_file(pca_data_info_path, lambda: df.info(verbose=True, show_counts=True))\n",
    "    \n",
    "create_final_data_files(final_data_df)\n",
    "create_pca_data_files(pca_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmps460",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
