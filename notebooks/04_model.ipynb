{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.ensemble as ske\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "FINAL_DATA_PATH = pathlib.Path('..') / 'data' / 'final' / 'final_data.csv'\n",
    "PCA_DATA_PATH = pathlib.Path('..') / 'data' / 'final' / 'pca_data.csv'\n",
    "\n",
    "final_data = pd.read_csv(FINAL_DATA_PATH)\n",
    "pca_data = pd.read_csv(PCA_DATA_PATH)\n",
    "\n",
    "X, y = final_data.drop('position', axis=1), final_data['position']\n",
    "pca_X, pca_y = pca_data, final_data['position']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "pca_X_train, pca_X_test, pca_y_train, pca_y_test = ms.train_test_split(pca_X, pca_y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Split train data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = ms.train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "X_train_features_count = X_train.shape[1]\n",
    "pca_X_train_features_count = pca_X_train.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inital Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ske.RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\"\"\" \n",
    "0 -> ST\n",
    "1 -> LW\n",
    "2 -> RW\n",
    "3 -> CM\n",
    "4 -> RB\n",
    "5 -> LB\n",
    "6 -> CB\n",
    "\"\"\"\n",
    "\n",
    "# Metrics\n",
    "print(skm.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "sns.barplot(x=feature_importance, y=feature_importance.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inital Model (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ske.RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rf.fit(pca_X_train, pca_y_train)\n",
    "y_pred = rf.predict(pca_X_test)\n",
    "\n",
    "\"\"\" \n",
    "0 -> ST\n",
    "1 -> LW\n",
    "2 -> RW\n",
    "3 -> CM\n",
    "4 -> RB\n",
    "5 -> LB\n",
    "6 -> CB\n",
    "\"\"\"\n",
    "\n",
    "# Metrics\n",
    "print(skm.classification_report(pca_y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(rf.feature_importances_, index=pca_X.columns).sort_values(ascending=False)\n",
    "sns.barplot(x=feature_importance, y=feature_importance.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lm.LogisticRegression(random_state=42, max_iter=1000, solver='lbfgs')\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(skm.classification_report(pca_y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow softmax ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "This model was tested with different number of layers and neurons per layer.\n",
    "The best result was achieved with the following configuration:\n",
    "    - 5 layers\n",
    "    - 256 neurons in the first layer\n",
    "    - 128 neurons in the second layer\n",
    "    - 64 neurons in the third layer\n",
    "    - 32 neurons in the fourth layer\n",
    "    - 7 neurons in the fifth layer\n",
    "\n",
    "The model was trained with 100 epochs and a batch size of 32.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# read model\n",
    "\n",
    "model = None\n",
    "try:\n",
    "    model = tf.keras.models.load_model('model.h5')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not model:\n",
    "    \n",
    "    input_size = X_train_features_count\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(input_size, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(7, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train model\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val)\n",
    "    )\n",
    "    \n",
    "\n",
    "# evaluate model\n",
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descirbe model\n",
    "model.summary()\n",
    "\n",
    "# save model\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "try:\n",
    "    model = pickle.load(open('randomforest_model.sav', 'rb'))\n",
    "except:\n",
    "    model = None\n",
    "    \n",
    "if not model:\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': [25, 50, 100, 150],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'max_depth': [6, 9, 12, 24, None],\n",
    "        'max_leaf_nodes': [6, 9, 12, 24, None],\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=15,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_n_estimators = grid_search.best_params_['n_estimators']\n",
    "    best_max_depth = grid_search.best_params_['max_depth']\n",
    "    best_max_features = grid_search.best_params_['max_features']\n",
    "    best_max_leaf_nodes = grid_search.best_params_['max_leaf_nodes']\n",
    "\n",
    "    best_model = RandomForestClassifier(\n",
    "        n_estimators=best_n_estimators,\n",
    "        max_depth=best_max_depth,\n",
    "        max_features=best_max_features,\n",
    "        max_leaf_nodes=best_max_leaf_nodes,\n",
    "    )\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    \n",
    "    # Save model\n",
    "    pickle.dump(best_model, open('randomforest_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{model.n_estimators=}\")\n",
    "print(f\"{model.max_depth=}\")\n",
    "print(f\"{model.max_features=}\")\n",
    "print(f\"{model.max_leaf_nodes=}\")\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmps460",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
